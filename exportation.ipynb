{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LCLid: string (nullable = true)\n",
      " |-- stdorToU: string (nullable = true)\n",
      " |-- DateTime: string (nullable = true)\n",
      " |-- KWH/hh (per half hour) : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "df = spark.read.option(\"header\",True).csv(\"data/CC_LCL-FullData.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"DateTime\",df.DateTime.astype('Timestamp'))\n",
    "#https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/\n",
    "df3=df.select(col(\"DateTime\"),\n",
    "             col(\"LCLid\").alias((\"id\")),\n",
    "            col(\"stdorToU\").alias(\"std\"),\n",
    "            col(\"KWH/hh (per half hour) \").alias(\"kwh\"),\n",
    "     year(col(\"DateTime\")).alias(\"year\"),\n",
    "     month(col(\"DateTime\")).alias(\"month\"),\n",
    "    dayofmonth(col(\"DateTime\")).alias(\"date\"),\n",
    "    hour(col(\"DateTime\")).alias(\"hour\"),\n",
    "    minute(col(\"DateTime\")).alias(\"min\"),\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167932474"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataset  consist from 165M++ rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Weather data\n",
    "df_weather = pd.read_csv(\"data/add/weather_hourly_darksky.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating date, time related columns\n",
    "df_weather = df_weather[['temperature', 'time']]\n",
    "df_weather.columns = ['temperature', 'DateTime']\n",
    "df_weather['DateTime'] = pd.to_datetime(df_weather['DateTime'])\n",
    "df_weather['year'] = df_weather['DateTime'].dt.year\n",
    "df_weather['month'] = df_weather['DateTime'].dt.month\n",
    "df_weather['day'] = df_weather['DateTime'].dt.day\n",
    "df_weather['time'] = df_weather['DateTime'].dt.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Weather information for the year 2013\n",
    "df_weather_2013 = df_weather[df_weather.year==2013][['temperature', 'month']]\n",
    "df_weather_2013 = df_weather_2013.groupby(by=['month'])['temperature'].mean().to_frame()\n",
    "df_weather_2013.reset_index(level=0, inplace=True)\n",
    "df_weather_2013.month = df_weather_2013.month.apply(lambda x: calendar.month_abbr[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Weather information for the year 2014\n",
    "df_weather_2014 = df_weather[df_weather.year==2014][['temperature', 'month']]\n",
    "df_weather_2014 = df_weather_2014.groupby(by=['month'])['temperature'].mean().to_frame()\n",
    "df_weather_2014.reset_index(level=0, inplace=True)\n",
    "df_weather_2014.month = df_weather_2014.month.apply(lambda x: calendar.month_abbr[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Household info data\n",
    "df_household = pd.read_csv(\"data/add/informations_households.csv\", encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24158"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "#filter the data for one househd\n",
    "df3.filter(df3.id=='MAC000002').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#household convert spark  dataframe\n",
    "householdd=spark.createDataFrame(df_household)\n",
    "\n",
    "#Join two DataSet\n",
    "df4=df3.join(householdd, df3.id == householdd.LCLid, 'left')\n",
    "df5=df4.withColumn(\"kwh\", df4.kwh.cast('double'))\n",
    "\n",
    "\n",
    "#convert string energy cosumtion data to double\n",
    "df5=df4.withColumn(\"kwh\", df4.kwh.cast('double'))\n",
    "\n",
    "#filter the data to perform to  a smaller sample all the\n",
    "dff=df3.filter(df3.id=='MAC000002')\n",
    "\n",
    "\n",
    "#innerjoin with household and energy\n",
    "#Apply filter to have better result\n",
    "df6=dff.join(householdd, dff.id == householdd.LCLid, 'left')\n",
    "#convert string to Chriss\n",
    "df7=df6.withColumn(\"kwh\", df6.kwh.cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before casting\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- std: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- date: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- sum(kwh): double (nullable = true)\n",
      "\n",
      "After casting\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- std: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- date: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- sum(kwh): double (nullable = true)\n",
      " |-- hours: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df8=df7.groupby(\"id\",\"std\",\"year\",\"month\",\"date\",\"hour\").sum(\"kwh\")\n",
    "\n",
    "\n",
    "print(\"Before casting\")\n",
    "df8.printSchema()\n",
    "df8_hours=df8.withColumn(\"hours\",df8['hour'].cast('integer'))\n",
    "print(\"After casting\")\n",
    "df8_hours.printSchema()\n",
    "\n",
    "pivot_df = df8_hours.groupby(\"id\",\"year\",\"month\",\"date\").pivot(\"hours\").sum(\"sum(kwh)\")\n",
    "\n",
    "\n",
    "#apply for all data in the dataset the aggregation sums\n",
    "\n",
    "#first we aggregate in hours , in this data set we have every half hour so we sum every hour\n",
    "# In the Eveddent dataset we do not need to aggredate every hour\n",
    "df_all8=df5.groupby(\"id\",\"std\",\"year\",\"month\",\"date\",\"hour\").sum(\"kwh\")\n",
    "#make ne aggregation per data\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "#create agragate columns for one day avg/max.min/standard division and sum of energy \n",
    "df_all_statistics=df5.groupby(\"id\",\"std\",\"year\",\"month\",\"date\").agg(f.sum(\"kwh\"),f.avg(\"kwh\"),f.max(\"kwh\"),f.min(\"kwh\"),f.count(\"kwh\"),f.stddev_pop(\"kwh\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='MAC000032', std='Std', year=2011, month=12, date=7, sum(kwh)=3.5269999999999997, avg(kwh)=0.15334782608695652, max(kwh)=0.692, min(kwh)=0.015, count(kwh)=23, stddev_pop(kwh)=0.20240609388825276),\n",
       " Row(id='MAC000032', std='Std', year=2011, month=12, date=8, sum(kwh)=17.6700001, avg(kwh)=0.3681250020833333, max(kwh)=2.5050001, min(kwh)=0.01, count(kwh)=48, stddev_pop(kwh)=0.5694364846124748),\n",
       " Row(id='MAC000032', std='Std', year=2011, month=12, date=9, sum(kwh)=18.41300040000001, avg(kwh)=0.38360417500000016, max(kwh)=2.5680001, min(kwh)=0.01, count(kwh)=48, stddev_pop(kwh)=0.6339574196381306),\n",
       " Row(id='MAC000032', std='Std', year=2011, month=12, date=10, sum(kwh)=21.75300010000001, avg(kwh)=0.4531875020833335, max(kwh)=2.586, min(kwh)=0.01, count(kwh)=48, stddev_pop(kwh)=0.6246162401870999),\n",
       " Row(id='MAC000032', std='Std', year=2011, month=12, date=11, sum(kwh)=19.146000000000004, avg(kwh)=0.3988750000000001, max(kwh)=2.648, min(kwh)=0.01, count(kwh)=48, stddev_pop(kwh)=0.6859822830863299)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the df\n",
    "df_all_statistics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='MAC000032', std='Std', year=2011, month=12, date=7, sum(kwh)=3.5269999999999997, avg(kwh)=0.15334782608695652, max(kwh)=0.692, min(kwh)=0.015, count(kwh)=23, stddev_pop(kwh)=0.20240609388825276)\n",
      "Row(id='MAC000032', std='Std', year=2011, month=12, date=8, sum(kwh)=17.6700001, avg(kwh)=0.3681250020833333, max(kwh)=2.5050001, min(kwh)=0.01, count(kwh)=48, stddev_pop(kwh)=0.5694364846124748)\n",
      "Row(id='MAC000032', std='Std', year=2011, month=12, date=9, sum(kwh)=18.41300040000001, avg(kwh)=0.38360417500000016, max(kwh)=2.5680001, min(kwh)=0.01, count(kwh)=48, stddev_pop(kwh)=0.6339574196381306)\n",
      "Row(id='MAC000032', std='Std', year=2011, month=12, date=10, sum(kwh)=21.75300010000001, avg(kwh)=0.4531875020833335, max(kwh)=2.586, min(kwh)=0.01, count(kwh)=48, stddev_pop(kwh)=0.6246162401870999)\n",
      "Row(id='MAC000032', std='Std', year=2011, month=12, date=11, sum(kwh)=19.146000000000004, avg(kwh)=0.3988750000000001, max(kwh)=2.648, min(kwh)=0.01, count(kwh)=48, stddev_pop(kwh)=0.6859822830863299)\n"
     ]
    }
   ],
   "source": [
    "#The previous print for better visual each row\n",
    "for i in df_all_statistics.head(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df_all_statistics is the final dayly aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3510433"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_all_statistics is the final dayly aggregation\n",
    "df_all_statistics.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before casting\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- std: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- date: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- sum(kwh): double (nullable = true)\n",
      "\n",
      "After casting\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- std: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- date: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- sum(kwh): double (nullable = true)\n",
      " |-- hours: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3510433"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Before casting\")\n",
    "df_all8.printSchema()\n",
    "\n",
    "df_all_hours=df_all8.withColumn(\"hours\",df_all8['hour'].cast('integer'))\n",
    "print(\"After casting\")\n",
    "df_all_hours.printSchema()\n",
    "pivot_df_all=df_all_hours.groupby(\"id\",\"year\",\"month\",\"date\").pivot(\"hours\").sum(\"sum(kwh)\")\n",
    "#dataset = pivot_df_all.groupby(\"id\",\"year\",\"month\",\"date\").sum(\"sum(kwh)\").avg(\"sum(kwh)\")(\"sum(kwh)\").min(\"sum(kwh)\").count(\"sum(kwh)\").std(\"sum(kwh)\")\n",
    "\n",
    "pivot_df_all.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Data freame was 165M. but aftew aggregation is 3.5M we set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to aggregation energy per, / year /months and weak days to plot and see the distubition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python385jvsc74a57bd0ed4335d6cbe1b4beeab2279141ac2539677c122e695ba2529d61d5b04ad0c51b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
